\section{Lessons Learned}\label{sec:cloud:lessons_learned}
In this chapter we examined tradeoffs between stakeholders in cloud environments.
As in the previously considered scenarios, various stakeholders exist, each with different and partially conflicting interests.
First, we considered the operation of a data centre from the point of view of a \emph{data centre operator}.
The data centre operator is interested in decreasing expenditures, e.g. due to energy consumption of computing equipment as well as in offering a competitive service to its customers.
The \emph{data centre customers} are interested in obtaining such services, usually by selecting them according to metrics specified in a \gls{SLA}.
One example of a metric considered in a \gls{SLA} is the delay a scheduled job is experiencing.

Second, we consider the role of the data centre customer in more detail.
Thus, we focus on a specific virtualised network function deployed in a data centre, and the customer in the role of a \emph{network function operator}.
The network function operator is interested in reducing the number of concurrent virtual machines provisioned, in order to decrease cost.
The network function operator in turn needs to satisfy its customers, the \emph{network function users}, who rely on the network function operator satisfying availability goals, e.g. the ability to connect to the Internet using \gls{GTP} tunnels.

Finally, we consider a human-cloud scenario.
Here, the \emph{crowdsourcing platform operator} attempts to balance the needs of its two stakeholders, the \emph{crowdsourcing employer} against the requirements of the \emph{crowdsourcing worker}.
Crowdsourcing employers publish tasks via the crowdsourcing platform to crowdsourcing employees and require a fast task completion time.
Crowdsourcing workers are interested in being offered as many tasks as possible, in order to increase their income.
Crowdsourcing platform operators can dimension the number of available crowdsourcing workers in order balance this tradeoff.

We draw three major conclusions from this chapter:

First, we observe that the proposed scheme for operation of the data centre allows for a reduction of the energy consumption by \SI{40}{\percent}.
As a tradeoff, the time before a task can begin processing is increased by less then \SI{1}{\milli\second}.
Furthermore, we show that for the considered mechanism, server deactivation should occur as soon as possible, resulting in the greatest energy savings while keeping an acceptable time until tasks can begin processing.

Second, we study the existence of configurations for the virtualised network function scenario, so that even for conservative server startup times, e.g. \SI{300}{\second}, the blocking probability increases only by a factor of 1.46.
This configuration also allows  \SI{45}{\percent} of the required instances to be used for other purposes at \SI{50}{\percent} of the time.
We also demonstrate that the observed blocking probability can be reduced by over \SI{90}{\percent} by employing techniques to reduce instance startup time, e.g. \glspl{SSD} or software containerisation.

Finally, we show that according to our model, crowdsourcing platforms are robust regarding different shapes of the arrival process, i.e. bursty arrivals compared to periodic arrivals.
Furthermore, we show that a relatively small number of workers is sufficient to sustain the platform during times of worker shortage, if the workers are put on retainer for the platform.

In the scenarios considered in this section, the platform operator is in control over parameters influencing the \glspl{KPI} for the participating stakeholders.
However, in all cases the \glspl{KPI} of the other stakeholders, by means of \gls{SLA} design, availability goals, or income, are also a \gls{KPI} for the platform operator.
This is due to the fact that not only one platform operator exists but multiple platform operators compete for customers.
Research on such multi-operator scenarios can be performed using the models introduced in this chapter.
